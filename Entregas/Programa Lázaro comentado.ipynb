{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70c1bada6409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import textdistance\n",
    "import folium\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "from statistics import mean \n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from unidecode import unidecode\n",
    "\n",
    "#####################################################################\n",
    "# remove special characters and stopwords from addresses\n",
    "\n",
    "STR_SPECIALCHAR = \"[({;:,<>_+=/.\\\"?!\\t\\r})]\"\n",
    "\n",
    "class getBiodiversity():\n",
    "    \n",
    "#####################################################################\n",
    "    # url: archive location\n",
    "    # key: Geocode key\n",
    "    #taxonomy_columns: filter to taxonomy level\n",
    "    #location_columns: filter to location\n",
    "    \n",
    "    def __init__(self, url, key, taxonomy_columns, location_columns): # Constructor method\n",
    "        self.url = url \n",
    "        self.geocoder = OpenCageGeocode(key)\n",
    "        self.TAXONOMY_COLUMNS = taxonomy_columns\n",
    "        self.LOCATION_COORDINATES = location_columns\n",
    "        \n",
    "        try: # function that trys to read de archive\n",
    "            self.df_data = pd.read_csv(url, sep=';', header=0, encoding='utf-8')\n",
    "        except Exception as e: # error message\n",
    "            self.df_data = pd.DataFrame()\n",
    "            print(\"Aborting... couldn't read this file: %s\" % url)\n",
    "            print (e.args)\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def getColumns(self): #Function to get dataframe columns name\n",
    "        self.df_columns = list(self.df_data.columns)\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def checkEmpty(self): # Function to check empty or \"Sem Informação\" and return the mean of missing informations\n",
    "        self.getColumns()\n",
    "        self.df_dataNAN = pd.DataFrame(np.where((self.df_data == '') | (self.df_data == 'Sem Informações'), 1, 0))\n",
    "        self.df_dataNAN.columns = self.df_columns\n",
    "        self.df_dataNAN = 100*self.df_dataNAN.mean()\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def getLastFilled(self, columns): #Function to search for last filled column\n",
    "        filled_columns = [column for column in columns if (column != \"Sem Informações\")]\n",
    "        return 'NA' if len(filled_columns) == 0 else self.TAXONOMY_COLUMNS[len(filled_columns)-1]\n",
    "######################################################################\n",
    "\n",
    "    def addTaxonomicLevel(self, col_name): # Return the count of the missing values by columns\n",
    "        self.df_data[col_name] = self.df_data[self.TAXONOMY_COLUMNS].apply(lambda x: self.getLastFilled(x), axis=1)\n",
    "        self.df_taxonomy_info =  self.df_data[col_name].value_counts()\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def extractTaxonomy(self, columns): # Get a copy of df_data columns\n",
    "        self.df_taxonomy = self.df_data[columns].copy()\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def getTaxonomy(self, col_name='taxonomic_level'): # Get the name of columns from TAXONOMY_COLUMNS\n",
    "        self.addTaxonomicLevel(col_name)\n",
    "        self.extractTaxonomy(self.TAXONOMY_COLUMNS+[col_name])\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def filterFields(self, columns, values): #Function that search for species in df_data\n",
    "        #filter = np.logical_and.reduce([self.df_data[columns[i]].isin(values[i]) for i in range(len(columns))])\n",
    "        filter = np.sum([self.df_data[columns[i]].isin(values[i])+(len(values[i])==0) for i in range(len(columns))], axis=0) == len(columns)\n",
    "        if columns: \n",
    "            self.df_filtered = self.df_data[filter].copy()\n",
    "        else:\n",
    "            self.df_filtered = self.df_data.copy()\n",
    "        return None\n",
    "######################################################################\n",
    "\n",
    "    def parseFloat(self, info): #Function that implements a parseFloat function\n",
    "        value = float(info)\n",
    "        try:\n",
    "            value = float(info)\n",
    "        except:\n",
    "            value = 0.0\n",
    "        return value\n",
    "######################################################################\n",
    "\n",
    "    \"\"\"\n",
    "    def checkGeoInfo(self, components, reported):\n",
    "        aux = []\n",
    "        unmatched = 0\n",
    "        for elem in [\"country\", \"state\", \"state_code\", \"city\"]:\n",
    "            try:\n",
    "                value = components[elem]\n",
    "            except:\n",
    "                value = \"NA\"\n",
    "            aux.append(value)\n",
    "        unmatched += 1 if reported[0] != aux[0] else 0\n",
    "        unmatched += 1 if not reported[1] in [aux[1], aux[2]] else 0\n",
    "        unmatched += 1 if reported[2] != aux[3] else 0\n",
    "        return unmatched\n",
    "    \"\"\"\n",
    "######################################################################\n",
    "\n",
    "    def removeStopWords(self, address): # Function that removes stop words\n",
    "        address = re.sub(STR_SPECIALCHAR, ' ', address).lower()\n",
    "        address = ' '.join([word.strip(' ') for word in address.split(' ') if word.strip(' ') not in self.STOP_WORDS])\n",
    "        return address\n",
    "######################################################################\n",
    "\n",
    "    def removeNonAscii(self, text): #Function that removes non ASCII character \n",
    "        return unidecode(str(text))\n",
    "######################################################################\n",
    "\n",
    "    def reverseGeocode(self, latlon):# Fuction to get address informations by latitude and longitude\n",
    "        geo = self.geocoder.reverse_geocode(latlon[0], latlon[1], no_annotations = '1', pretty = '1', language='pt')\n",
    "        #comp = geo[0]['components']\n",
    "        #similarity = self.checkGeoInfo(comp, [latlon[2], latlon[3], latlon[4]])\n",
    "        reversed = self.removeStopWords(geo[0]['formatted']) #apply the removeStopWords function on Geocoder results\n",
    "        reported = self.removeStopWords(' '.join(latlon[2:6]))\n",
    "        reversed = self.removeNonAscii(reversed) #apply the removeNonAscii function on Geocoder results\n",
    "        reported = self.removeNonAscii(reported)\n",
    "        similarity = 100 * textdistance.jaccard(reported , reversed) #get the text distance (similarity) by jaccard method\n",
    "        return pd.Series((reported, reversed, similarity))\n",
    "######################################################################\n",
    "\n",
    "    def setMapZoom(self, coords): #Function to sets map zoom by latitude and longitude\n",
    "        try:\n",
    "            rangelat = math.sqrt(170 / (max(coords[0][:])-min(coords[0][:]))) \n",
    "            rangelon = math.sqrt(360 / (max(coords[1][:])-min(coords[1][:])))\n",
    "            zoom = int(min(rangelat, rangelon)) + 1\n",
    "        except:\n",
    "            zoom = 1\n",
    "        return zoom\n",
    "######################################################################\n",
    "\n",
    "    \"\"\"\n",
    "    def printMap(self):\n",
    "        coords = self.df_location_sample[[\"lat\", \"lon\", \"ReversedAddress\", \"Similarity\"]].T.values.tolist()\n",
    "        COLORS = ['green', 'lightgreen', 'orange', 'red']\n",
    "        center = [mean(coords[0][:]), mean(coords[1][:])]\n",
    "        zoom = self.setMapZoom(coords[0:2][:])\n",
    "        my_map = folium.Map(location=center, zoom_start=zoom, tiles=\"OpenStreetMap\")\n",
    "        for i in range(len(self.df_location_sample)):\n",
    "            folium.Marker(location=[coords[0][i], coords[1][i]], popup=coords[2][i], \n",
    "                          icon=folium.Icon(color=COLORS[coords[3][i]], icon='map-marker')).add_to(my_map) \n",
    "        self.observations_map = my_map\n",
    "        return None\n",
    "    \"\"\"\n",
    "######################################################################\n",
    "\n",
    "    def checkCoordinates(self, size):\n",
    "        try:\n",
    "            stopwords = open(\"stopwords.txt\") # open txt with stopwords\n",
    "            self.STOP_WORDS = [linha.rstrip(\" \").rstrip(\"\\n\") for linha in stopwords.readlines()]\n",
    "        except:\n",
    "            self.STOP_WORDS = [\"asdfasdfasdf\"] # if stopwords file not found\n",
    "        self.STOP_WORDS = [sw.lower().strip() for sw in set(self.STOP_WORDS)]\n",
    "        self.df_filtered[\"lat\"] = self.df_data[\"Latitude\"].apply(lambda x: self.parseFloat(x))\n",
    "        self.df_filtered[\"lon\"] = self.df_data[\"Longitude\"].apply(lambda x: self.parseFloat(x))\n",
    "        if len(self.df_filtered) < size:\n",
    "            print(\"Not enough data to show. Please check your filter opetions\")\n",
    "            self.df_location_sample = pd.DataFrame()\n",
    "            self.observations_map = None\n",
    "            return None\n",
    "        self.df_location_sample = self.df_filtered.sample(n=size).copy()\n",
    "        self.df_location_sample[['ReportedAddress','ReversedAddress','Similarity']] = self.df_location_sample[['lat','lon']+self.LOCATION_COORDINATES].apply(self.reverseGeocode, axis=1)\n",
    "        #self.printMap()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:exerc_python] *",
   "language": "python",
   "name": "conda-env-exerc_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
